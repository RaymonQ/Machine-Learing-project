import numpy as np
import pandas as pd
from sklearn.naive_bayes import MultinomialNB, BernoulliNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

data = pd.read_csv('training.csv')
test = pd.read_csv('test.csv')
data = data[data.topic != 'IRRELEVANT']
test = test[test.topic != 'IRRELEVANT']
Topic = {'ARTS CULTURE ENTERTAINMENT': 1,'BIOGRAPHIES PERSONALITIES PEOPLE': 2,'DEFENCE': 3,'DOMESTIC MARKETS': 4,'FOREX MARKETS': 5,'HEALTH': 6,'MONEY MARKETS': 7,'SCIENCE AND TECHNOLOGY': 8,'SHARE LISTINGS': 9,'SPORTS': 10}
data.topic = [Topic[item] for item in data.topic]
test.topic = [Topic[item] for item in test.topic]
X = data['article_words']
Y = data['topic']
X_test = test['article_words']
Y_test = test['topic']


cv = CountVectorizer(strip_accents='ascii', token_pattern=u'(?ui)\\b\\w*[a-z]+\\w*\\b', lowercase=True, stop_words='english')
X_cv = cv.fit_transform(X)
X_test_cv = cv.transform(X_test)

word_freq_df = pd.DataFrame(X_cv.toarray(), columns=cv.get_feature_names())
top_words_df = pd.DataFrame(word_freq_df.sum()).sort_values(0, ascending=False)

from sklearn.naive_bayes import MultinomialNB
naive_bayes = MultinomialNB()
naive_bayes.fit(X_cv, Y)
predictions = naive_bayes.predict(X_test_cv)

from sklearn.metrics import accuracy_score, precision_score, recall_score
print('Accuracy score:', accuracy_score(Y_test, predictions))
print('Precision score:', precision_score(Y_test, predictions,average='macro'))
print('Recall score:', recall_score(Y_test, predictions,average='macro'))
